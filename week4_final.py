
import pandas as pd
import numpy as np
import re
from sklearn.model_selection import cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv("/content/drive/MyDrive/titanic_data/train.csv")
test = pd.read_csv("/content/drive/MyDrive/titanic_data/test.csv")
test_ids = test['PassengerId']

# 2. ì „ì²˜ë¦¬ ë° Feature Engineering í•¨ìˆ˜
def preprocess(df):
    df = df.copy()

    # ì„±ë³„ ì¸ì½”ë”©
    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})

    # Title ì¶”ì¶œ ë° ê°„ì†Œí™”
    def extract_title(name):
        match = re.search(r' ([A-Za-z]+)\.', name)
        return match.group(1) if match else "None"

    df['Title'] = df['Name'].apply(extract_title)
    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')
    df['Title'] = df['Title'].replace('Mme', 'Mrs')
    df['Title'] = df['Title'].replace(
        ['Lady', 'Countess','Capt','Col','Don','Dr','Major',
         'Rev','Sir','Jonkheer','Dona'], 'Rare'
    )
    df['Title'] = df['Title'].apply(lambda x: x if x in ['Mr', 'Miss', 'Mrs', 'Master'] else 'Rare')

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df['Age'] = df['Age'].fillna(df['Age'].median())
    df['Fare'] = df['Fare'].fillna(df['Fare'].median())
    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])

    # IsAlone íŒŒìƒ ë³€ìˆ˜
    df['IsAlone'] = ((df['SibSp'] + df['Parch']) == 0).astype(int)

    # Fare êµ¬ê°„í™”
    df['FareBin'] = pd.qcut(df['Fare'], 4, labels=False)

    # ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
    df = df.drop(columns=['Cabin', 'Ticket', 'Name'])

    # ì›í•« ì¸ì½”ë”©
    df = pd.get_dummies(df, columns=['Title', 'Embarked'], drop_first=True)

    return df

# 3. ì „ì²˜ë¦¬ ì‹¤í–‰
train_proc = preprocess(train)
test_proc = preprocess(test)

X = train_proc.drop(columns=['Survived', 'PassengerId'])
y = train_proc['Survived']
X_test_final = test_proc.drop(columns=['PassengerId'])
X_test_final = X_test_final[X.columns]

# 4. ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_test_scaled = scaler.transform(X_test_final)

# 5. ëª¨ë¸ ì •ì˜
models = {
    'LogisticRegression': LogisticRegression(max_iter=1000),
    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42)
}

# 6. ëª¨ë¸ í‰ê°€
results = {}
for name, model in models.items():
    print(f"\nâ–¶ Evaluating: {name}")
    preds = cross_val_predict(model, X_scaled, y, cv=5)
    acc = accuracy_score(y, preds)
    prec = precision_score(y, preds)
    rec = recall_score(y, preds)
    f1 = f1_score(y, preds)
    cm = confusion_matrix(y, preds)

    model.fit(X_scaled, y)

    results[name] = {
        'model': model,
        'accuracy': acc,
        'precision': prec,
        'recall': rec,
        'f1': f1,
        'confusion_matrix': cm
    }

    print(f"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}")
    print("Confusion Matrix:\n", cm)

# 7. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
best_model_name = max(results, key=lambda x: results[x]['accuracy'])
best_model = results[best_model_name]['model']
best_acc = results[best_model_name]['accuracy']
print(f"\nâœ… Best model selected: {best_model_name} (Accuracy: {best_acc:.4f})")

# 8. í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±
preds = best_model.predict(X_test_scaled)
submission = pd.DataFrame({
    'PassengerId': test_ids,
    'Survived': preds
})
filename = f"titanic_best_simplified_{best_model_name}_acc{best_acc:.4f}.csv"
submission.to_csv(filename, index=False)
print(f"\nğŸ“ ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
